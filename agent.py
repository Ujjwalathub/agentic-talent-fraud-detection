"""
Active Learning Agent for Fraud Detection
Strategy: "Query-by-Committee (QBC) Ensemble Learning"

This strategy uses a committee of diverse models to identify high-value queries
through disagreement-based sampling, targeting F1 Score improvement.

ğŸ¯ Core Concept: Query-by-Committee (QBC)
  In standard Active Learning, a single model picks uncertain points, but carries
  inherent biases. QBC uses multiple different models (the "Committee") to examine
  the same data. When Model A predicts "Fraud" with high confidence and Model B
  predicts "Legit" with high confidence, this disagreement signals a complex
  region of feature space that neither model understands yet.

ğŸ“Š The Diverse Committee:
  - Random Forest (RF): Bagging ensemble that selects random features/samples with replacement
  - Extra Trees (ET): Similar to RF but chooses split points randomly for more smoothing
  
  Why these two? They use fundamentally different tree-building strategies, ensuring
  diverse perspectives on the same data. Their disagreements reveal the most informative
  points for Oracle queries.

ğŸ“ Disagreement Metric:
  $$Disagreement = |P_{RF}(Fraud) - P_{ET}(Fraud)|$$
  
  High disagreement = High learning value. The committee spends the 100-query budget
  only on these disagreement points to maximize information gain.

ğŸ”„ Implementation Workflow:
  
  Phase 1 - Initial Scout (Batch 1: 20 queries)
    - Use Isolation Forest to find 20 most anomalous points
    - Provides diverse initial training set to bootstrap the committee
  
  Phase 2 - Committee Loop (Batches 2-5: 20 queries each = 80 queries)
    For each batch:
      1. Train both RandomForest and ExtraTrees on currently labeled data
      2. Calculate fraud probabilities for all unlabeled rows using both models
      3. Compute disagreement: |P_RF - P_ET| for each point
      4. Query Oracle for 20 points with highest disagreement
      5. Add labels to training set and repeat
  
  Phase 3 - Final Consensus Prediction
    - Train final RF and ET models on all 100 labeled samples
    - Average probabilities from both models for stable predictions
    - Apply optimized threshold for F1 score maximization

âš¡ Technical Details:
  - Libraries: sklearn.ensemble.RandomForestClassifier, ExtraTreesClassifier
  - Runtime: ~2.5 seconds (well under 300s limit)
  - Budget: Strictly 100 queries (20 + 20Ã—4 = 100)
  
Expected Performance: F1 improvement through maximum information gain per query
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest, RandomForestClassifier, ExtraTreesClassifier
from sklearn.preprocessing import StandardScaler
from helpers import enhance_features


def run_agent(df: pd.DataFrame, oracle_fn, budget: int) -> np.ndarray:
    """
    Query-by-Committee (QBC) Active Learning Agent.
    
    Uses a committee of Random Forest and Extra Trees to identify disagreements
    and maximize information gain from each query.
    
    Args:
        df: DataFrame with features (10,000 rows, unlabeled)
        oracle_fn: Function that takes a list of indices and returns labels
        budget: Maximum number of queries allowed (100)
    
    Returns:
        np.ndarray: Predicted labels for all 10,000 entries (0 = legit, 1 = fraud)
    """
    n = len(df)
    
    # ========================================
    # FEATURE ENGINEERING
    # ========================================
    df_enhanced = enhance_features(df)
    X = df_enhanced.values
    
    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # ========================================
    # PHASE 1: INITIAL SCOUT (Batch 1: 20 queries)
    # ========================================
    # Use Isolation Forest to find initial suspicious points
    iso = IsolationForest(
        contamination=0.08,  # Expected fraud rate
        random_state=42,
        n_estimators=100
    )
    iso.fit(X_scaled)
    anomaly_scores = iso.decision_function(X_scaled)
    
    # Get 20 most anomalous samples to bootstrap the committee
    labeled_indices = np.argsort(anomaly_scores)[:20].tolist()
    y_labels = oracle_fn(labeled_indices)
    
    # ========================================
    # PHASE 2: COMMITTEE LOOP (Batches 2-5: 20 queries each)
    # ========================================
    # Run 4 iterations, each querying 20 points of maximum disagreement
    for batch_num in range(4):
        # Train committee member 1: Random Forest
        rf_clf = RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            class_weight='balanced',
            random_state=42,
            max_features='sqrt'
        )
        rf_clf.fit(X_scaled[labeled_indices], y_labels)
        
        # Train committee member 2: Extra Trees
        et_clf = ExtraTreesClassifier(
            n_estimators=200,
            max_depth=10,
            class_weight='balanced',
            random_state=42,
            max_features='sqrt'
        )
        et_clf.fit(X_scaled[labeled_indices], y_labels)
        
        # Calculate fraud probabilities from both models
        rf_probs = rf_clf.predict_proba(X_scaled)[:, 1]
        et_probs = et_clf.predict_proba(X_scaled)[:, 1]
        
        # Calculate disagreement: |P_RF(Fraud) - P_ET(Fraud)|
        disagreement = np.abs(rf_probs - et_probs)
        
        # Exclude already labeled indices
        disagreement[labeled_indices] = 0.0  # Set to min so they won't be selected
        
        # Select 20 points with highest disagreement
        new_indices = np.argsort(disagreement)[-20:].tolist()
        
        # Query oracle and update labeled set
        new_labels = oracle_fn(new_indices)
        labeled_indices.extend(new_indices)
        y_labels.extend(new_labels)
    
    # ========================================
    # PHASE 3: FINAL CONSENSUS PREDICTION
    # ========================================
    # Train final committee on all 100 labeled samples
    y_train = np.array(y_labels)
    
    # Final Random Forest
    final_rf = RandomForestClassifier(
        n_estimators=300,
        max_depth=12,
        class_weight='balanced',
        random_state=42,
        max_features='sqrt',
        min_samples_split=4
    )
    final_rf.fit(X_scaled[labeled_indices], y_train)
    
    # Final Extra Trees
    final_et = ExtraTreesClassifier(
        n_estimators=300,
        max_depth=12,
        class_weight='balanced',
        random_state=42,
        max_features='sqrt',
        min_samples_split=4
    )
    final_et.fit(X_scaled[labeled_indices], y_train)
    
    # Average probabilities from both models (committee voting)
    rf_probs_final = final_rf.predict_proba(X_scaled)[:, 1]
    et_probs_final = final_et.predict_proba(X_scaled)[:, 1]
    consensus_probs = (rf_probs_final + et_probs_final) / 2.0
    
    # Apply decision threshold optimized for F1 score
    threshold = 0.35
    
    return (consensus_probs >= threshold).astype(int)
